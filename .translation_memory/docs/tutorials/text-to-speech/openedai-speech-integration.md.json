{
  "source_file_path_relative_to_docusaurus_root": "docs/tutorials/text-to-speech/openedai-speech-integration.md",
  "source_file_content_hash": "42543584c1a482c65c5c4d2d7f3d9faed3e2a58d34438f74fb6f11633db0db00",
  "segments": [
    {
      "segment_id": "58cfcc64",
      "source_content": "---\nsidebar_position: 2\ntitle: \"ğŸ—¨ï¸ Openedai-speech Using Docker\"\n---",
      "source_content_hash": "7b0c0536cd9f3701aee11027c6f3cddb400d801931b59631de7b9bfc80fc5539",
      "node_type": "yaml",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_58cfcc64"
      }
    },
    {
      "segment_id": "0eeea6cc",
      "source_content": ":::warning\nThis tutorial is a community contribution and is not supported by the Sage WebUI team. It serves only as a demonstration on how to customize Sage WebUI for your specific use case. Want to contribute? Check out the contributing tutorial.\n:::",
      "source_content_hash": "9deffb738cd50d6595571ff813d2388bdda279aad6934a7d7fdfb239906531ed",
      "node_type": "containerDirective",
      "translatable": true,
      "translations": {
        "ja": ":::warning\nã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã‚ˆã‚‹å¯„ç¨¿ã§ã‚ã‚Šã€Sage WebUIãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«åˆã‚ã›ã¦Sage WebUIã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹æ–¹æ³•ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã®ã¿æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚å¯„ç¨¿ã—ãŸã„ã§ã™ã‹ï¼Ÿå¯„ç¨¿ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚\n:::"
      }
    },
    {
      "segment_id": "1cc03ec8",
      "source_content": "**Integrating `openedai-speech` into Sage WebUI using Docker**\n==============================================================",
      "source_content_hash": "eb72a53dffeb82095f2fa71c5ed669e648286f91384b0470cc9a94276b61167a",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**Dockerã‚’ä½¿ç”¨ã—ã¦Sage WebUIã«`openedai-speech`ã‚’çµ±åˆã™ã‚‹**\n=============================================================="
      }
    },
    {
      "segment_id": "ba4f48ff",
      "source_content": "**What is `openedai-speech`?**\n-----------------------------",
      "source_content_hash": "71801a067e8dfd00ca0dccf483bbf02ef88d05c04e960bd0e5cac716230b8d34",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**`openedai-speech`ã¨ã¯ï¼Ÿ**\n-----------------------------"
      }
    },
    {
      "segment_id": "976d532b",
      "source_content": ":::info\n[openedai-speech](https://github.com/matatonic/openedai-speech) is an OpenAI audio/speech API compatible text-to-speech server.\n\nIt serves the `/v1/audio/speech` endpoint and provides a free, private text-to-speech experience with custom voice cloning capabilities. This service is in no way affiliated with OpenAI and does not require an OpenAI API key.\n:::",
      "source_content_hash": "79d4debbac91f654bf19985e19343c11168954f6a0a7fce8164f9002b5226b35",
      "node_type": "containerDirective",
      "translatable": true,
      "translations": {
        "ja": ":::info\n[openedai-speech](https://github.com/matatonic/openedai-speech)ã¯ã€OpenAIã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª/éŸ³å£°APIã¨äº’æ›æ€§ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚\n\n`/v1/audio/speech`ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›ã—ã€ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚’å‚™ãˆãŸç„¡æ–™ã®ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ä½“é¨“ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯OpenAIã¨ã¯ä¸€åˆ‡é–¢ä¿‚ãŒãªãã€OpenAIã®APIã‚­ãƒ¼ã‚‚å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚\n:::"
      }
    },
    {
      "segment_id": "63622bf0",
      "source_content": "**Requirements**\n-----------------",
      "source_content_hash": "505997002ea080d4d441560b4026d150b1d67c86a9ad83ec09274daf6beb0d4c",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**è¦ä»¶**\n-----------------"
      }
    },
    {
      "segment_id": "44d89370",
      "source_content": "* Docker installed on your system\n* Sage WebUI running in a Docker container\n* Basic understanding of Docker and Docker Compose",
      "source_content_hash": "761898a56980576cb4326d0f5254e224a5f7e0f208b1ebf8f8a5da4bd84e8c26",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* ã‚·ã‚¹ãƒ†ãƒ ã«DockerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n* Sage WebUIãŒDockerã‚³ãƒ³ãƒ†ãƒŠã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã“ã¨\n* Dockerã¨Docker Composeã®åŸºæœ¬çš„ãªç†è§£"
      }
    },
    {
      "segment_id": "f2f30ae8",
      "source_content": "**Option 1: Using Docker Compose**\n----------------------------------",
      "source_content_hash": "d99a8af0ce3fb4573cc42903ad282ded50623ac1d3f386bbafb6ead49a59b462",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚ªãƒ—ã‚·ãƒ§ãƒ³1: Docker Composeã‚’ä½¿ç”¨ã™ã‚‹**\n----------------------------------"
      }
    },
    {
      "segment_id": "b25f21be",
      "source_content": "**Step 1: Create a new folder for the `openedai-speech` service**\n-----------------------------------------------------------------",
      "source_content_hash": "8a869a93d2c7e0205d63c9afbda23d603127beacbda4494333b4de3cfdf1a3b8",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—1: `openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã®ãŸã‚ã®æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã™ã‚‹**\n-----------------------------------------------------------------"
      }
    },
    {
      "segment_id": "bdc231b1",
      "source_content": "Create a new folder, for example, `openedai-speech-service`, to store the `docker-compose.yml` and `speech.env` files.",
      "source_content_hash": "c5872e105183b2e429f747b1f54b42f6c8d03bda4b5290b2893ed92214b1607e",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`openedai-speech-service`ãªã©ã®æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€`docker-compose.yml`ã¨`speech.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã™ã€‚"
      }
    },
    {
      "segment_id": "3b7478ea",
      "source_content": "**Step 2: Clone the `openedai-speech` repository from GitHub**\n--------------------------------------------------------------",
      "source_content_hash": "5a71e8bb328c7f379317bca40a4ff41767616967b8e4fa8287bd02b873ef57bc",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—2: GitHubã‹ã‚‰`openedai-speech`ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹**\n--------------------------------------------------------------"
      }
    },
    {
      "segment_id": "a11df754",
      "source_content": "```bash\ngit clone https://github.com/matatonic/openedai-speech.git\n```",
      "source_content_hash": "530d41a531c8ee455fe1d56a771c0caaa3dee84637aac3e7d24c5a5391313fe7",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_a11df754"
      }
    },
    {
      "segment_id": "95e9ba12",
      "source_content": "This will download the `openedai-speech` repository to your local machine, which includes the Docker Compose files (`docker-compose.yml`, `docker-compose.min.yml`, and `docker-compose.rocm.yml`) and other necessary files.",
      "source_content_hash": "b5f562594cb0b4ab701a05fb81508f4d4a87c9d1a0cb071bf3b46b809f90447d",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ã“ã‚Œã«ã‚ˆã‚Šã€`openedai-speech`ãƒªãƒã‚¸ãƒˆãƒªãŒãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚ãƒªãƒã‚¸ãƒˆãƒªã«ã¯Docker Composeãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`docker-compose.yml`ã€`docker-compose.min.yml`ã€`docker-compose.rocm.yml`ï¼‰ã‚„ãã®ä»–ã®å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
      }
    },
    {
      "segment_id": "8bddee80",
      "source_content": "**Step 3: Rename the `sample.env` file to `speech.env` (Customize if needed)**\n------------------------------------------------------------------------------",
      "source_content_hash": "7e6f55a6c7eb3837ef1e2e16d688d3dd7953406d6435c2604d30986247627562",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—3: `sample.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’`speech.env`ã«ãƒªãƒãƒ¼ãƒ ã™ã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼‰**\n------------------------------------------------------------------------------"
      }
    },
    {
      "segment_id": "29528c8d",
      "source_content": "In the `openedai-speech` repository folder, create a new file named `speech.env` with the following contents:",
      "source_content_hash": "a0fc32ac176f0ba37c96c7ebf7afb276157479c938ebff471f348a26f2e6585b",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`openedai-speech`ãƒªãƒã‚¸ãƒˆãƒªãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã€ä»¥ä¸‹ã®å†…å®¹ã§`speech.env`ã¨ã„ã†åå‰ã®æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼š"
      }
    },
    {
      "segment_id": "4795a13d",
      "source_content": "```yaml\nTTS_HOME=voices\nHF_HOME=voices\n#PRELOAD_MODEL=xtts\n#PRELOAD_MODEL=xtts_v2.0.2\n#PRELOAD_MODEL=parler-tts/parler_tts_mini_v0.1\n#EXTRA_ARGS=--log-level DEBUG --unload-timer 300\n#USE_ROCM=1\n```",
      "source_content_hash": "3b64200e9e82c578e7d412ad0190c03530b2bd252606c678dc1c2ca630ad4305",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_4795a13d"
      }
    },
    {
      "segment_id": "e912d935",
      "source_content": "**Step 4: Choose a Docker Compose file**\n----------------------------------------",
      "source_content_hash": "1d9f63b27e2389fb269da5059c08dcf3225af33764aef5da9ebb5bca064b64a9",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—4: Docker Composeãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹**\n----------------------------------------"
      }
    },
    {
      "segment_id": "79ad944d",
      "source_content": "You can use any of the following Docker Compose files:",
      "source_content_hash": "361cbdc254d904117d797fbb9e250a59a0e3fda0d409baeef6f369bf374bdf5d",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®Docker Composeãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ï¼š"
      }
    },
    {
      "segment_id": "2eb5ba30",
      "source_content": "* [docker-compose.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.yml): This file uses the `ghcr.io/matatonic/openedai-speech` image and builds from [Dockerfile](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile).\n* [docker-compose.min.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.min.yml): This file uses the `ghcr.io/matatonic/openedai-speech-min` image and builds from [Dockerfile.min](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile.min).\n  This image is a minimal version that only includes Piper support and does not require a GPU.\n* [docker-compose.rocm.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.rocm.yml): This file uses the `ghcr.io/matatonic/openedai-speech-rocm` image and builds from [Dockerfile](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile) with ROCm support.",
      "source_content_hash": "a758271a5515c7249edf0c504a26ef9f392e345751d364b25dfffe1085a26560",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* [docker-compose.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.yml): ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯`ghcr.io/matatonic/openedai-speech`ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã€[Dockerfile](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile)ã‹ã‚‰ãƒ“ãƒ«ãƒ‰ã—ã¾ã™ã€‚\n* [docker-compose.min.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.min.yml): ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯`ghcr.io/matatonic/openedai-speech-min`ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã€[Dockerfile.min](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile.min)ã‹ã‚‰ãƒ“ãƒ«ãƒ‰ã—ã¾ã™ã€‚\n  ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯Piperã‚µãƒãƒ¼ãƒˆã®ã¿ã‚’å«ã‚€æœ€å°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã€GPUã‚’å¿…è¦ã¨ã—ã¾ã›ã‚“ã€‚\n* [docker-compose.rocm.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.rocm.yml): ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯`ghcr.io/matatonic/openedai-speech-rocm`ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã€ROCmã‚µãƒãƒ¼ãƒˆã‚’å‚™ãˆãŸ[Dockerfile](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile)ã‹ã‚‰ãƒ“ãƒ«ãƒ‰ã—ã¾ã™ã€‚"
      }
    },
    {
      "segment_id": "52388877",
      "source_content": "**Step 4: Build the Chosen Docker Image**\n-----------------------------------------",
      "source_content_hash": "4cc008a27711ed4871df209fe79ccc8ff5ada6fc539b5cc8abdfe663f355a389",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—4: é¸æŠã—ãŸDockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã™ã‚‹**\n-----------------------------------------"
      }
    },
    {
      "segment_id": "883231d4",
      "source_content": "Before running the Docker Compose file, you need to build the Docker image:",
      "source_content_hash": "3c6e50e4dd95dc4a014d1f305ee016bce2dbb768c64537fadfa5e348ec572cb5",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Docker Composeãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š"
      }
    },
    {
      "segment_id": "4fe53981",
      "source_content": "* **Nvidia GPU (CUDA support)**:",
      "source_content_hash": "e1e81070bfb776dfb5048267bbdef6518d050595d2bfe9f7fe7ded8aa5f220fa",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **Nvidia GPU (CUDAã‚µãƒãƒ¼ãƒˆ)**:"
      }
    },
    {
      "segment_id": "8a9e710a",
      "source_content": "```bash\ndocker build -t ghcr.io/matatonic/openedai-speech .\n```",
      "source_content_hash": "d8611e9bcfc3487940072a2e9123ff36ff690b51e66e0198f9757e41f951f8d3",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_8a9e710a"
      }
    },
    {
      "segment_id": "c0ea80dd",
      "source_content": "* **AMD GPU (ROCm support)**:",
      "source_content_hash": "8db7be0bde2069025e0a44cf5c6f64cae117d597389498e17cc1b0e6fe56fbdb",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **AMD GPU (ROCmã‚µãƒãƒ¼ãƒˆ)**:"
      }
    },
    {
      "segment_id": "d8159289",
      "source_content": "```bash\ndocker build -f Dockerfile --build-arg USE_ROCM=1 -t ghcr.io/matatonic/openedai-speech-rocm .\n```",
      "source_content_hash": "c66598cb9946b9e974ebb9b44f4552b31313073439c9c0a2487ffcb9014e11df",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_d8159289"
      }
    },
    {
      "segment_id": "887c863e",
      "source_content": "* **CPU only, No GPU (Piper only)**:",
      "source_content_hash": "44a84df91310a36bdd50968578a08ac07a70df076d200e90e13d3e57c5205283",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **CPUã®ã¿ã€GPUãªã—ï¼ˆPiperã®ã¿ï¼‰**:"
      }
    },
    {
      "segment_id": "7d898a0e",
      "source_content": "```bash\ndocker build -f Dockerfile.min -t ghcr.io/matatonic/openedai-speech-min .\n```",
      "source_content_hash": "a7535cb4e16f2f5254ee522f07a6e843679ee834ba61e4e4d4037b790cade07c",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_7d898a0e"
      }
    },
    {
      "segment_id": "f6b04a59",
      "source_content": "**Step 5: Run the correct `docker compose up -d` command**\n----------------------------------------------------------",
      "source_content_hash": "4c89e3c79939f747a1534c055ec5e7da5c673b3cceba9462909a7a31a516fb4c",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—5: æ­£ã—ã„`docker compose up -d`ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹**\n----------------------------------------------------------"
      }
    },
    {
      "segment_id": "b264104e",
      "source_content": "* **Nvidia GPU (CUDA support)**: Run the following command to start the `openedai-speech` service in detached mode:",
      "source_content_hash": "0f92e9cd2463b749f7032ba3d29d74364e216387f29238029d93e81775c7e14e",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **NVIDIA GPUï¼ˆCUDAã‚µãƒãƒ¼ãƒˆï¼‰**: ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ‡ã‚¿ãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™:"
      }
    },
    {
      "segment_id": "890e01bc",
      "source_content": "```bash\ndocker compose up -d\n```",
      "source_content_hash": "3e7b856b2044030c0e7e938c22308c9ec4f465a67d5cc331338d0265378e244e",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_890e01bc"
      }
    },
    {
      "segment_id": "584b7213",
      "source_content": "* **AMD GPU (ROCm support)**: Run the following command to start the `openedai-speech` service in detached mode:",
      "source_content_hash": "8a23d4ae31233c95f2060d2b57454668fa2848b7b12f936a3d5be18e0cdc66b5",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **AMD GPUï¼ˆROCmã‚µãƒãƒ¼ãƒˆï¼‰**: ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ‡ã‚¿ãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™:"
      }
    },
    {
      "segment_id": "64071bcc",
      "source_content": "```bash\ndocker compose -f docker-compose.rocm.yml up -d\n```",
      "source_content_hash": "44f7ee9a5cf5b502277ff12df7593d2f8189c54b2bd1d8438c0435fd99290722",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_64071bcc"
      }
    },
    {
      "segment_id": "664ad8b1",
      "source_content": "* **ARM64 (Apple M-series, Raspberry Pi)**: XTTS only has CPU support here and will be very slow. You can use the Nvidia image for XTTS with CPU (slow), or use the Piper only image (recommended):",
      "source_content_hash": "a895a9649b9c9928575e70d8b97ff2ef7f95c1dc5cfd68d5c700bebe92d8a3f3",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **ARM64ï¼ˆApple Mã‚·ãƒªãƒ¼ã‚ºã€Raspberry Piï¼‰**: XTTSã¯ã“ã“ã§ã¯CPUã‚µãƒãƒ¼ãƒˆã®ã¿ã§éå¸¸ã«é…ããªã‚Šã¾ã™ã€‚XTTSç”¨ã®NVIDIAã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’CPUã§ä½¿ç”¨ã™ã‚‹ï¼ˆé…ã„ï¼‰ã‹ã€Piperã®ã¿ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã™ã‚‹ï¼ˆæ¨å¥¨ï¼‰ã“ã¨ãŒã§ãã¾ã™:"
      }
    },
    {
      "segment_id": "59534425",
      "source_content": "```bash\ndocker compose -f docker-compose.min.yml up -d\n```",
      "source_content_hash": "cccd45fccd824425b6706549d1f25aad8c99f96d8d42a9e22432ca8fdf5b30c0",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_59534425"
      }
    },
    {
      "segment_id": "0422e2e2",
      "source_content": "* **CPU only, No GPU (Piper only)**: For a minimal docker image with only Piper support (< 1GB vs. 8GB):",
      "source_content_hash": "d8f83433fb12e5cda2aa0fd09ca8c5db58d3a5109744b68f2feae027f699586f",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **CPUã®ã¿ã€GPUãªã—ï¼ˆPiperã®ã¿ï¼‰**: Piperã‚µãƒãƒ¼ãƒˆã®ã¿ã®æœ€å°é™ã®Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆ< 1GB vs. 8GBï¼‰ã®å ´åˆ:"
      }
    },
    {
      "segment_id": "342e4d80",
      "source_content": "```bash\ndocker compose -f docker-compose.min.yml up -d\n```",
      "source_content_hash": "cccd45fccd824425b6706549d1f25aad8c99f96d8d42a9e22432ca8fdf5b30c0",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_342e4d80"
      }
    },
    {
      "segment_id": "a8610918",
      "source_content": "This will start the `openedai-speech` service in detached mode.",
      "source_content_hash": "6aef84d51afbc1d6eeb059b79ef6116979610a753515becd1ab6235c9012d6c9",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ã“ã‚Œã«ã‚ˆã‚Šã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ãŒãƒ‡ã‚¿ãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ã€‚"
      }
    },
    {
      "segment_id": "b9b8694c",
      "source_content": "**Option 2: Using Docker Run Commands**\n---------------------------------------",
      "source_content_hash": "9f58892e75f7e5012476ddcedcb7fbbf5bfd247ed4917f3f5d56ce3284b6445c",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: Docker Runã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹**\n---------------------------------------"
      }
    },
    {
      "segment_id": "5f82a1e9",
      "source_content": "You can also use the following Docker run commands to start the `openedai-speech` service in detached mode:",
      "source_content_hash": "bd6cca16a5db6b9a15f37561fbd4c1bade073b22c4f4675330aca957694f64ff",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ä»¥ä¸‹ã®Docker runã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ‡ã‚¿ãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™:"
      }
    },
    {
      "segment_id": "683a33d9",
      "source_content": "* **Nvidia GPU (CUDA)**: Run the following command to build and start the `openedai-speech` service:",
      "source_content_hash": "d8f7c5c810388fbe6e8af4fd4ad28ca68ab8fe9411ccf672e701e471b81b2dac",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **NVIDIA GPUï¼ˆCUDAï¼‰**: ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ãŠã‚ˆã³èµ·å‹•ã—ã¾ã™:"
      }
    },
    {
      "segment_id": "a3a1b8eb",
      "source_content": "```bash\ndocker build -t ghcr.io/matatonic/openedai-speech .\ndocker run -d --gpus=all -p 8000:8000 -v voices:/app/voices -v config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech\n```",
      "source_content_hash": "a8b5f3f151f0dca05ca11440771dcc3c6d9420b7462b3d6d9073052319885b41",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_a3a1b8eb"
      }
    },
    {
      "segment_id": "6409152f",
      "source_content": "* **ROCm (AMD GPU)**: Run the following command to build and start the `openedai-speech` service:",
      "source_content_hash": "8f283a29ae429d186b58e182ce5a613d1012faafe6f2bf64f3bdd05674f428d6",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **ROCmï¼ˆAMD GPUï¼‰**: ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ãŠã‚ˆã³èµ·å‹•ã—ã¾ã™:"
      }
    },
    {
      "segment_id": "bfcbf7c6",
      "source_content": "> To enable ROCm support, uncomment the `#USE_ROCM=1` line in the `speech.env` file.",
      "source_content_hash": "4053ed1a38f2507cd0ca9d8485b3b91276890dff321bd6fbe3942faf4215f147",
      "node_type": "blockquote",
      "translatable": true,
      "translations": {
        "ja": "> ROCmã‚µãƒãƒ¼ãƒˆã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€`speech.env`ãƒ•ã‚¡ã‚¤ãƒ«ã®`#USE_ROCM=1`è¡Œã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’è§£é™¤ã—ã¦ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "4c6754b2",
      "source_content": "```bash\ndocker build -f Dockerfile --build-arg USE_ROCM=1 -t ghcr.io/matatonic/openedai-speech-rocm .\ndocker run -d --privileged --init --name openedai-speech -p 8000:8000 -v voices:/app/voices -v config:/app/config ghcr.io/matatonic/openedai-speech-rocm\n```",
      "source_content_hash": "f36ca72f6a3609e3bca7248dda2b7388286cb3e7ecba98ca1d471072c43f0770",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_4c6754b2"
      }
    },
    {
      "segment_id": "31bf14c2",
      "source_content": "* **CPU only, No GPU (Piper only)**: Run the following command to build and start the `openedai-speech` service:",
      "source_content_hash": "91461f0e7463c2a714a923b9a80476cdea5f6bca395a9f76d6b22bcae7c0ed56",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **CPUã®ã¿ã€GPUãªã—ï¼ˆPiperã®ã¿ï¼‰**: ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ“ãƒ«ãƒ‰ãŠã‚ˆã³èµ·å‹•ã—ã¾ã™:"
      }
    },
    {
      "segment_id": "4fe849d4",
      "source_content": "```bash\ndocker build -f Dockerfile.min -t ghcr.io/matatonic/openedai-speech-min .\ndocker run -d -p 8000:8000 -v voices:/app/voices -v config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech-min\n```",
      "source_content_hash": "1ca6bf5fbb666e0f48ea88af64de79a8e53e1e93a802f9b185d0bbbb36d5ec44",
      "node_type": "code",
      "translatable": false,
      "translations": {
        "ja": "@@untranslatable_placeholder_4fe849d4"
      }
    },
    {
      "segment_id": "3cd8185f",
      "source_content": "**Step 6: Configuring Sage WebUI to use `openedai-speech` for TTS**\n---------------------------------------------------------",
      "source_content_hash": "34c6969b700a90d6e90449dd9074af6fde67bf09f4b1037e0529628d35df9fe8",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—6: Sage WebUIã‚’è¨­å®šã—ã¦`openedai-speech`ã‚’TTSã«ä½¿ç”¨ã™ã‚‹**\n---------------------------------------------------------"
      }
    },
    {
      "segment_id": "42d9ca67",
      "source_content": "![openedai-tts](https://github.com/silentoplayz/docs/assets/50341825/ea08494f-2ebf-41a2-bb0f-9b48dd3ace79)",
      "source_content_hash": "c7c6eca32116cd57999a2f7c518831933b0c32838b27ea4a524ee4827b9bd862",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "![openedai-tts](https://github.com/silentoplayz/docs/assets/50341825/ea08494f-2ebf-41a2-bb0f-9b48dd3ace79)"
      }
    },
    {
      "segment_id": "619c3209",
      "source_content": "Open the Sage WebUI settings and navigate to the TTS Settings under **Admin Panel > Settings > Audio**. Add the following configuration:",
      "source_content_hash": "5d956a1c370f62ca825891e8316ab14aabebde526f4c4c9a8e1c179b3342cbb8",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Sage WebUIã®è¨­å®šã‚’é–‹ãã€**ç®¡ç†ãƒ‘ãƒãƒ« > è¨­å®š > ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª**ã®ä¸‹ã«ã‚ã‚‹TTSè¨­å®šã«ç§»å‹•ã—ã¾ã™ã€‚ä»¥ä¸‹ã®è¨­å®šã‚’è¿½åŠ ã—ã¦ãã ã•ã„:"
      }
    },
    {
      "segment_id": "9fbd2efb",
      "source_content": "* **API Base URL**: `http://host.docker.internal:8000/v1`\n* **API Key**: `sk-111111111` (Note that this is a dummy API key, as `openedai-speech` doesn't require an API key. You can use whatever you'd like for this field, as long as it is filled.)",
      "source_content_hash": "c13e1275a3b3d218cad0c4059b05b6d2f8319f1a407460b836dae92519c68ccc",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **APIãƒ™ãƒ¼ã‚¹URL**: `http://host.docker.internal:8000/v1`\n* **APIã‚­ãƒ¼**: `sk-111111111`ï¼ˆã“ã‚Œã¯ãƒ€ãƒŸãƒ¼ã®APIã‚­ãƒ¼ã§ã™ã€‚`openedai-speech`ã¯APIã‚­ãƒ¼ã‚’å¿…è¦ã¨ã—ã¾ã›ã‚“ã€‚ã“ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ä½•ã‚’å…¥ã‚Œã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€å…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ï¼‰"
      }
    },
    {
      "segment_id": "3c6dd548",
      "source_content": "**Step 7: Choose a voice**\n--------------------------",
      "source_content_hash": "53a56f9d9efca915cd7cfa55014e1777675543a25a899f94e8bd7b724b6078d5",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—7: éŸ³å£°ã‚’é¸æŠã™ã‚‹**\n--------------------------"
      }
    },
    {
      "segment_id": "008183b0",
      "source_content": "Under `TTS Voice` within the same audio settings menu in the admin panel, you can set the `TTS Model` to use from the following choices below that `openedai-speech` supports. The voices of these models are optimized for the English language.",
      "source_content_hash": "ee7ed967c9f78942bea4dc159aba9f90103f2e58aa37759cdd7d44850bce128d",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ç®¡ç†ãƒ‘ãƒãƒ«ã®åŒã˜ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¨­å®šãƒ¡ãƒ‹ãƒ¥ãƒ¼å†…ã®`TTS Voice`ã§ã€ä»¥ä¸‹ã®`openedai-speech`ãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹`TTS Model`ã‚’è¨­å®šã§ãã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®éŸ³å£°ã¯è‹±èªç”¨ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚"
      }
    },
    {
      "segment_id": "e258929d",
      "source_content": "* `tts-1` or `tts-1-hd`: `alloy`, `echo`, `echo-alt`, `fable`, `onyx`, `nova`, and `shimmer` (`tts-1-hd` is configurable; uses OpenAI samples by default)",
      "source_content_hash": "63044e729c698bde1052e394c46dc6e03d2d869a37e95460c788eede58334fdb",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* `tts-1`ã¾ãŸã¯`tts-1-hd`: `alloy`, `echo`, `echo-alt`, `fable`, `onyx`, `nova`, `shimmer`ï¼ˆ`tts-1-hd`ã¯è¨­å®šå¯èƒ½ï¼›ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§OpenAIã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ï¼‰"
      }
    },
    {
      "segment_id": "08f73f73",
      "source_content": "**Step 8: Press `Save` to apply the changes and start enjoying naturally sounding voices**\n--------------------------------------------------------------------------------------------",
      "source_content_hash": "59b29ab2e2123700560daa9d696124859fd92bc8ef7bd008e781ae12a02372b2",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ã‚¹ãƒ†ãƒƒãƒ—8: `ä¿å­˜`ã‚’æŠ¼ã—ã¦å¤‰æ›´ã‚’é©ç”¨ã—ã€è‡ªç„¶ãªéŸ³å£°ã‚’æ¥½ã—ã‚€**\n--------------------------------------------------------------------------------------------"
      }
    },
    {
      "segment_id": "827eb9a3",
      "source_content": "Press the `Save` button to apply the changes to your Sage WebUI settings. Refresh the page for the change to fully take effect and enjoy using `openedai-speech` integration within Sage WebUI to read aloud text responses with text-to-speech in a natural sounding voice.",
      "source_content_hash": "54952fa3b0ea6df9a3f91d6e1d65b1a1c2955a6243321fff3bd3058c09f1fff3",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`ä¿å­˜`ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€Sage WebUIã®è¨­å®šã«å¤‰æ›´ã‚’é©ç”¨ã—ã¾ã™ã€‚ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦å¤‰æ›´ã‚’å®Œå…¨ã«åæ˜ ã•ã›ã€Sage WebUIå†…ã§`openedai-speech`çµ±åˆã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’è‡ªç„¶ãªéŸ³å£°ã§èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ã‚’æ¥½ã—ã‚“ã§ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "6ffd1ebe",
      "source_content": "**Model Details:**\n------------------",
      "source_content_hash": "a7cff92e936240e3157f0a8a15beed054ef7dfe01f756e302d3a0c0a5df7905c",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°:**\n------------------"
      }
    },
    {
      "segment_id": "85ea22dd",
      "source_content": "`openedai-speech` supports multiple text-to-speech models, each with its own strengths and requirements. The following models are available:",
      "source_content_hash": "e83f37a79d6cdf9429abe7b4ca77d4ded855556e64d24608bf57a60f53208e9f",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`openedai-speech`ã¯ã€ãã‚Œãã‚Œç‹¬è‡ªã®å¼·ã¿ã¨è¦ä»¶ã‚’æŒã¤è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™:"
      }
    },
    {
      "segment_id": "db79148c",
      "source_content": "* **Piper TTS** (very fast, runs on CPU): Use your own [Piper voices](https://rhasspy.github.io/piper-samples/) via the `voice_to_speaker.yaml` configuration file. This model is great for applications that require low latency and high performance. Piper TTS also supports [multilingual](https://github.com/matatonic/openedai-speech#multilingual) voices.\n* **Coqui AI/TTS XTTS v2** (fast, but requires around 4GB GPU VRAM & Nvidia GPU with CUDA): This model uses Coqui AI's XTTS v2 voice cloning technology to generate high-quality voices. While it requires a more powerful GPU, it provides excellent performance and high-quality audio. Coqui also supports [multilingual](https://github.com/matatonic/openedai-speech#multilingual) voices.\n* **Beta Parler-TTS Support** (experimental, slower): This model uses the Parler-TTS framework to generate voices. While it's currently in beta, it allows you to describe very basic features of the speaker voice. The exact voice will be slightly different with each generation, but should be similar to the speaker description provided. For inspiration on how to describe voices, see [Text Description to Speech](https://www.text-description-to-speech.com/).",
      "source_content_hash": "fd0ac33606f95ed2dc80969a5378e627d092002366ab8fb0f86af8511fc1592c",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **Piper TTS**ï¼ˆéå¸¸ã«é«˜é€Ÿã€CPUã§å‹•ä½œï¼‰: [Piper voices](https://rhasspy.github.io/piper-samples/)ã‚’`voice_to_speaker.yaml`è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ä½é…å»¶ã¨é«˜æ€§èƒ½ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«æœ€é©ã§ã™ã€‚Piper TTSã¯[å¤šè¨€èª](https://github.com/matatonic/openedai-speech#multilingual)éŸ³å£°ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n* **Coqui AI/TTS XTTS v2**ï¼ˆé«˜é€Ÿã§ã™ãŒã€ç´„4GBã®GPU VRAMã¨Nvidia GPUï¼ˆCUDAå¯¾å¿œï¼‰ãŒå¿…è¦ï¼‰: ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯Coqui AIã®XTTS v2éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦é«˜å“è³ªãªéŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã‚ˆã‚Šå¼·åŠ›ãªGPUãŒå¿…è¦ã§ã™ãŒã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨é«˜å“è³ªãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’æä¾›ã—ã¾ã™ã€‚Coquiã‚‚[å¤šè¨€èª](https://github.com/matatonic/openedai-speech#multilingual)éŸ³å£°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n* **Beta Parler-TTSã‚µãƒãƒ¼ãƒˆ**ï¼ˆå®Ÿé¨“çš„ã€ä½é€Ÿï¼‰: ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯Parler-TTSãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ç¾åœ¨ã¯ãƒ™ãƒ¼ã‚¿ç‰ˆã§ã™ãŒã€è©±è€…ã®å£°ã®éå¸¸ã«åŸºæœ¬çš„ãªç‰¹å¾´ã‚’è¨˜è¿°ã§ãã¾ã™ã€‚ç”Ÿæˆã”ã¨ã«æ­£ç¢ºãªå£°ã¯å°‘ã—ç•°ãªã‚Šã¾ã™ãŒã€æä¾›ã•ã‚ŒãŸè©±è€…ã®èª¬æ˜ã¨ä¼¼ãŸã‚‚ã®ã«ãªã‚Šã¾ã™ã€‚å£°ã®è¨˜è¿°æ–¹æ³•ã®ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã¯ã€[Text Description to Speech](https://www.text-description-to-speech.com/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "c66e62ef",
      "source_content": "**Troubleshooting**\n-------------------",
      "source_content_hash": "e5aef4bf73433e650811382d98331926d1a0485039253699f74d2b457b7387a4",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**\n-------------------"
      }
    },
    {
      "segment_id": "e5821418",
      "source_content": "If you encounter any problems integrating `openedai-speech` with Sage WebUI, follow these troubleshooting steps:",
      "source_content_hash": "d48ea77be207dc0377599a06b80430246f61bc6f67f84e7bf3b040e44b7acc49",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Sage WebUIã¨`openedai-speech`ã®çµ±åˆã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„ï¼š"
      }
    },
    {
      "segment_id": "9cfc9f06",
      "source_content": "* **Verify `openedai-speech` service**: Ensure that the `openedai-speech` service is running and the port you specified in the docker-compose.yml file is exposed.\n* **Check access to host.docker.internal**: Verify that the hostname `host.docker.internal` is resolvable from within the Sage WebUI container. This is necessary because `openedai-speech` is exposed via `localhost` on your PC, but `sage-open-webui` cannot normally access it from inside its container. You can add a volume to the `docker-compose.yml` file to mount a file from the host to the container, for example, to a directory that will be served by openedai-speech.\n* **Review API key configuration**: Make sure the API key is set to a dummy value or effectively left unchecked because `openedai-speech` doesn't require an API key.\n* **Check voice configuration**: Verify that the voice you are trying to use for TTS exists in your `voice_to_speaker.yaml` file and the corresponding files (e.g., voice XML files) are present in the correct directory.\n* **Verify voice model paths**: If you're experiencing issues with voice model loading, double-check that the paths in your `voice_to_speaker.yaml` file match the actual locations of your voice models.",
      "source_content_hash": "9871c903c8452e8e4c7e80e104bbcc34ae19cc5c125f2363a2ec6be4957398c3",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* **`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã®ç¢ºèª**: `openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ãŒå®Ÿè¡Œä¸­ã§ã‚ã‚Šã€docker-compose.ymlãƒ•ã‚¡ã‚¤ãƒ«ã§æŒ‡å®šã—ãŸãƒãƒ¼ãƒˆãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n* **host.docker.internalã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª**: Sage WebUIã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰ãƒ›ã‚¹ãƒˆå`host.docker.internal`ãŒè§£æ±ºå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯ã€`openedai-speech`ãŒPCã®`localhost`ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ãŒã€`sage-open-webui`ã¯é€šå¸¸ã‚³ãƒ³ãƒ†ãƒŠå†…ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚å¿…è¦ã§ã™ã€‚ãŸã¨ãˆã°ã€ãƒ›ã‚¹ãƒˆã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒŠã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã«ã€`docker-compose.yml`ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’è¿½åŠ ã§ãã¾ã™ã€‚\n* **APIã‚­ãƒ¼è¨­å®šã®ç¢ºèª**: APIã‚­ãƒ¼ãŒãƒ€ãƒŸãƒ¼å€¤ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã€ã¾ãŸã¯`openedai-speech`ãŒAPIã‚­ãƒ¼ã‚’å¿…è¦ã¨ã—ãªã„ãŸã‚ã€å®Ÿè³ªçš„ã«ãƒã‚§ãƒƒã‚¯ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n* **éŸ³å£°è¨­å®šã®ç¢ºèª**: TTSã«ä½¿ç”¨ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹éŸ³å£°ãŒ`voice_to_speaker.yaml`ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã—ã€å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¾‹ï¼šéŸ³å£°XMLãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ãŒæ­£ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n* **éŸ³å£°ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®ç¢ºèª**: éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã€`voice_to_speaker.yaml`ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ‘ã‚¹ãŒéŸ³å£°ãƒ¢ãƒ‡ãƒ«ã®å®Ÿéš›ã®å ´æ‰€ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã“ã¨ã‚’å†ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "6d457467",
      "source_content": "**Additional Troubleshooting Tips**\n------------------------------------",
      "source_content_hash": "7f2504197455918691e4c9eaf41e6c497c6ef8c2e1654d68d156ae96c36eb25d",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**è¿½åŠ ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®ãƒ’ãƒ³ãƒˆ**\n------------------------------------"
      }
    },
    {
      "segment_id": "e612e1d0",
      "source_content": "* Check the openedai-speech logs for errors or warnings that might indicate where the issue lies.\n* Verify that the `docker-compose.yml` file is correctly configured for your environment.\n* If you're still experiencing issues, try restarting the `openedai-speech` service or the entire Docker environment.\n* If the problem persists, consult the `openedai-speech` GitHub repository or seek help on a relevant community forum.",
      "source_content_hash": "55b9b55dfa77464d0f8a6dac6b056e0abee5109142ca283647c43b50469c3339",
      "node_type": "list",
      "translatable": true,
      "translations": {
        "ja": "* openedai-speechã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã€å•é¡Œã®åŸå› ã‚’ç¤ºã™ã‚¨ãƒ©ãƒ¼ã‚„è­¦å‘ŠãŒãªã„ã‹èª¿ã¹ã¦ãã ã•ã„ã€‚\n* `docker-compose.yml`ãƒ•ã‚¡ã‚¤ãƒ«ãŒç’°å¢ƒã«åˆã‚ã›ã¦æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n* å•é¡ŒãŒè§£æ±ºã—ãªã„å ´åˆã¯ã€`openedai-speech`ã‚µãƒ¼ãƒ“ã‚¹ã¾ãŸã¯Dockerç’°å¢ƒå…¨ä½“ã‚’å†èµ·å‹•ã—ã¦ã¿ã¦ãã ã•ã„ã€‚\n* å•é¡ŒãŒç¶šãå ´åˆã¯ã€`openedai-speech`ã®GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’å‚ç…§ã™ã‚‹ã‹ã€é–¢é€£ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã§åŠ©ã‘ã‚’æ±‚ã‚ã¦ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "4d7a4554",
      "source_content": "**FAQ**\n-------",
      "source_content_hash": "3052d83123a8e761500d3db2a55dc84c0a6ead7b7094cc7bed17dfe3ebe21901",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**FAQ**\n-------"
      }
    },
    {
      "segment_id": "48249e3c",
      "source_content": "**How can I control the emotional range of the generated audio?**",
      "source_content_hash": "5eebb2a30caf497acb9f7727814b5e02599e943b47ccaca0d16e16fec9e20113",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "**ç”Ÿæˆã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®æ„Ÿæƒ…ç¯„å›²ã‚’åˆ¶å¾¡ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ**"
      }
    },
    {
      "segment_id": "ebfad7e4",
      "source_content": "There is no direct mechanism to control the emotional output of the generated audio. Certain factors such as capitalization or grammar may affect the output audio, but internal testing has yielded mixed results.",
      "source_content_hash": "8d4e6901ddea085046775b331a8b1a37247732400e40475906763f081c83c3d8",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "ç”Ÿæˆã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®æ„Ÿæƒ…å‡ºåŠ›ã‚’ç›´æ¥åˆ¶å¾¡ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¤§æ–‡å­—åŒ–ã‚„æ–‡æ³•ãªã©ã®ç‰¹å®šã®è¦å› ãŒå‡ºåŠ›ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€å†…éƒ¨ãƒ†ã‚¹ãƒˆã§ã¯çµæœãŒã¾ã¡ã¾ã¡ã§ã—ãŸã€‚"
      }
    },
    {
      "segment_id": "7e563909",
      "source_content": "**Where are the voice files stored? What about the configuration file?**.",
      "source_content_hash": "08556700fa6ac64195512cffde608c407447d580802e7223f7f33e4ecb6bf9c6",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "**éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã©ã“ã«ä¿å­˜ã•ã‚Œã¾ã™ã‹ï¼Ÿè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ã©ã†ã§ã™ã‹ï¼Ÿ**"
      }
    },
    {
      "segment_id": "90c4b96b",
      "source_content": "The configuration files, which define the available voices and their properties, are stored in the config volume. Specifically, the default voices are defined in voice_to_speaker.default.yaml.",
      "source_content_hash": "e887991073577a65b9396eddb01d89e0b7e0cd44de1e34d6de29ccf61ed9a039",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåˆ©ç”¨å¯èƒ½ãªéŸ³å£°ã¨ãã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å®šç¾©ã™ã‚‹ï¼‰ã¯configãƒœãƒªãƒ¥ãƒ¼ãƒ ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®éŸ³å£°ã¯`voice_to_speaker.default.yaml`ã§å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚"
      }
    },
    {
      "segment_id": "197e1a1b",
      "source_content": "**Additional Resources**\n------------------------",
      "source_content_hash": "59252bda9b1f81590b1abe0f031f3a64b07760b21a1264d25d93a3b69cae6fe9",
      "node_type": "heading",
      "translatable": true,
      "translations": {
        "ja": "**è¿½åŠ ãƒªã‚½ãƒ¼ã‚¹**\n------------------------"
      }
    },
    {
      "segment_id": "af834e0d",
      "source_content": "For more information on configuring Sage WebUI to use `openedai-speech`, including setting environment variables, see the [Sage WebUI documentation](/getting-started/env-configuration#text-to-speech).",
      "source_content_hash": "edbeb6c899f452ee0b486701c2b94f25c5c637e751954862261d1f2b923506e1",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "Sage WebUIã§`openedai-speech`ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã®è¨­å®šã‚’å«ã‚€ï¼‰ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[Sage WebUIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](/getting-started/env-configuration#text-to-speech)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "d75361e3",
      "source_content": "For more information about `openedai-speech`, please visit the [GitHub repository](https://github.com/matatonic/openedai-speech).",
      "source_content_hash": "bb2cab828ff36594531ecab94a704e2c86fc2ce52266db1e3f1f0b80df49f017",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "`openedai-speech`ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/matatonic/openedai-speech)ã‚’ã”è¦§ãã ã•ã„ã€‚"
      }
    },
    {
      "segment_id": "c277c3c0",
      "source_content": "**How to add more voices to openedai-speech:**\n[Custom-Voices-HowTo](https://github.com/matatonic/openedai-speech?tab=readme-ov-file#custom-voices-howto)",
      "source_content_hash": "66e1b08eae483bdb2207aa13f500d4984e46be8b21a4e6843a28b0d240bf9336",
      "node_type": "paragraph",
      "translatable": true,
      "translations": {
        "ja": "**openedai-speechã«éŸ³å£°ã‚’è¿½åŠ ã™ã‚‹æ–¹æ³•:**\n[ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°è¿½åŠ ã‚¬ã‚¤ãƒ‰](https://github.com/matatonic/openedai-speech?tab=readme-ov-file#custom-voices-howto)"
      }
    },
    {
      "segment_id": "59087b4e",
      "source_content": ":::note\nYou can change the port number in the `docker-compose.yml` file to any open and usable port, but be sure to update the **API Base URL** in Sage WebUI Admin Audio settings accordingly.\n:::",
      "source_content_hash": "da6e2d4ae8c659cc679501341a70e578806acdb3215fbb89018a7c7ebca8922b",
      "node_type": "containerDirective",
      "translatable": true,
      "translations": {
        "ja": ":::note\n`docker-compose.yml`ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒãƒ¼ãƒˆç•ªå·ã‚’å¤‰æ›´å¯èƒ½ã§ã™ãŒã€Sage WebUIç®¡ç†è€…ç”»é¢ã®Audioè¨­å®šã«ã‚ã‚‹**API Base URL**ã‚‚åˆã‚ã›ã¦æ›´æ–°ã—ã¦ãã ã•ã„ã€‚\n:::"
      }
    }
  ],
  "target_i18n_subpath": "docusaurus-plugin-content-docs/current/tutorials/text-to-speech/openedai-speech-integration.md",
  "last_updated_timestamp": "2025-06-06T09:21:13.781414+00:00",
  "schema_version": "1.0",
  "translated_versions": {
    "ja": "42543584c1a482c65c5c4d2d7f3d9faed3e2a58d34438f74fb6f11633db0db00"
  }
}