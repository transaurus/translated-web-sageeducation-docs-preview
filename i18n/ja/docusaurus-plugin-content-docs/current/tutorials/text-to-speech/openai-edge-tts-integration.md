---
sidebar_position: 1
title: "ğŸ—¨ï¸ Edge TTS Using Docker"
---

:::warning
ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã‚ˆã‚‹å¯„ç¨¿ã§ã‚ã‚Šã€Sage WebUIãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«åˆã‚ã›ã¦Sage WebUIã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹æ–¹æ³•ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã®ã¿æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚å¯„ç¨¿ã‚’ã”å¸Œæœ›ã§ã™ã‹ï¼Ÿå¯„ç¨¿ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚
:::

# Sage WebUIã¨`openai-edge-tts` ğŸ—£ï¸ã®çµ±åˆ

## `openai-edge-tts`ã¨ã¯ï¼Ÿ

[OpenAI Edge TTS](https://github.com/travisvn/openai-edge-tts)ã¯ã€OpenAI APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ¨¡å€£ã—ãŸãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’APIã§ã™ã€‚Sage WebUIã®ã‚ˆã†ã«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLã‚’å®šç¾©ã§ãã‚‹ã‚·ãƒŠãƒªã‚ªã§ç›´æ¥ä»£æ›¿ã¨ã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚

ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯[edge-tts](https://github.com/rany2/edge-tts)ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€Edgeãƒ–ãƒ©ã‚¦ã‚¶ã®ç„¡æ–™ã€ŒéŸ³å£°èª­ã¿ä¸Šã’ã€æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã¦Microsoft/Azureã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€ç„¡æ–™ã§éå¸¸ã«é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

[éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã¯ã“ã¡ã‚‰](https://tts.travisvn.com)

<details>
  <summary>How is it different from 'openedai-speech'?</summary>

Similar to [openedai-speech](https://github.com/matatonic/openedai-speech), [openai-edge-tts](https://github.com/travisvn/openai-edge-tts) is a text-to-speech API endpoint that mimics the OpenAI API endpoint, allowing for a direct substitute in scenarios where the OpenAI Speech endpoint is callable and the server endpoint URL can be configured.

`openedai-speech` is a more comprehensive option that allows for entirely offline generation of speech with many modalities to choose from.

`openai-edge-tts` is a simpler option that uses a Python package called `edge-tts` to generate the audio.

</details>

## è¦ä»¶

- ã‚·ã‚¹ãƒ†ãƒ ã«DockerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨
- Sage WebUIãŒå‹•ä½œã—ã¦ã„ã‚‹ã“ã¨

## âš¡ï¸ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

ä½•ã‚‚è¨­å®šã›ãšã«æœ€ã‚‚ç°¡å˜ã«å§‹ã‚ã‚‹æ–¹æ³•ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã™

```bash
docker run -d -p 5050:5050 travisvn/openai-edge-tts:latest
```

ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ãƒãƒ¼ãƒˆ5050ã§ã‚µãƒ¼ãƒ“ã‚¹ãŒå®Ÿè¡Œã•ã‚Œã¾ã™

## Sage WebUIã§`openai-edge-tts`ã‚’ä½¿ç”¨ã™ã‚‹è¨­å®š

- ç®¡ç†ãƒ‘ãƒãƒ«ã‚’é–‹ãã€`è¨­å®š` -> `éŸ³å£°`ã«ç§»å‹•ã—ã¾ã™
- TTSè¨­å®šã‚’ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã¨ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã™
- _æ³¨ï¼šã“ã“ã§TTSéŸ³å£°ã‚’æŒ‡å®šã§ãã¾ã™_

![ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç”¨ã®æ­£ã—ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ ã—ãŸSage WebUIç®¡ç†ç”»é¢ã®éŸ³å£°è¨­å®šã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ](https://utfs.io/f/MMMHiQ1TQaBobmOhsMkrO6Tl2kxX39dbuFiQ8cAoNzysIt7f)

:::info
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®APIã‚­ãƒ¼ã¯æ–‡å­—åˆ—`your_api_key_here`ã§ã™ã€‚è¿½åŠ ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãŒå¿…è¦ãªã„å ´åˆã¯ã€ã“ã®å€¤ã‚’å¤‰æ›´ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
:::

**ã“ã‚Œã§å®Œäº†ã§ã™ï¼ã“ã“ã§çµ‚äº†ã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“**

# [OpenAI Edge TTS](https://github.com/travisvn/openai-edge-tts)ãŒå½¹ç«‹ã¤ã¨æ€ã£ãŸã‚‰ã€GitHubã§â­ï¸ã‚¹ã‚¿ãƒ¼ã‚’ä»˜ã‘ã¦ãã ã•ã„

<details>
  <summary>Running with Python</summary>
  
### ğŸ Running with Python

If you prefer to run this project directly with Python, follow these steps to set up a virtual environment, install dependencies, and start the server.

#### 1. Clone the Repository

```bash
git clone https://github.com/travisvn/openai-edge-tts.git
cd openai-edge-tts
```

#### 2. Set Up a Virtual Environment

Create and activate a virtual environment to isolate dependencies:

```bash
# For macOS/Linux
python3 -m venv venv
source venv/bin/activate

# For Windows
python -m venv venv
venv\Scripts\activate
```

#### 3. Install Dependencies

Use `pip` to install the required packages listed in `requirements.txt`:

```bash
pip install -r requirements.txt
```

#### 4. Configure Environment Variables

Create a `.env` file in the root directory and set the following variables:

```plaintext
API_KEY=your_api_key_here
PORT=5050

DEFAULT_VOICE=en-US-AvaNeural
DEFAULT_RESPONSE_FORMAT=mp3
DEFAULT_SPEED=1.0

DEFAULT_LANGUAGE=en-US

REQUIRE_API_KEY=True
REMOVE_FILTER=False
EXPAND_API=True
```

#### 5. Run the Server

Once configured, start the server with:

```bash
python app/server.py
```

The server will start running at `http://localhost:5050`.

#### 6. Test the API

You can now interact with the API at `http://localhost:5050/v1/audio/speech` and other available endpoints. See the Usage section for request examples.

</details>

<details>
  <summary>Usage details</summary>
  
##### Endpoint: `/v1/audio/speech` (aliased with `/audio/speech`)

Generates audio from the input text. Available parameters:

**Required Parameter:**

- **input** (string): The text to be converted to audio (up to 4096 characters).

**Optional Parameters:**

- **model** (string): Set to "tts-1" or "tts-1-hd" (default: `"tts-1"`).
- **voice** (string): One of the OpenAI-compatible voices (alloy, echo, fable, onyx, nova, shimmer) or any valid `edge-tts` voice (default: `"en-US-AvaNeural"`).
- **response_format** (string): Audio format. Options: `mp3`, `opus`, `aac`, `flac`, `wav`, `pcm` (default: `mp3`).
- **speed** (number): Playback speed (0.25 to 4.0). Default is `1.0`.

:::tip
You can browse available voices and listen to sample previews at [tts.travisvn.com](https://tts.travisvn.com)
:::

Example request with `curl` and saving the output to an mp3 file:

```bash
curl -X POST http://localhost:5050/v1/audio/speech \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_api_key_here" \
  -d '{
    "input": "Hello, I am your AI assistant! Just let me know how I can help bring your ideas to life.",
    "voice": "echo",
    "response_format": "mp3",
    "speed": 1.0
  }' \
  --output speech.mp3
```

Or, to be in line with the OpenAI API endpoint parameters:

```bash
curl -X POST http://localhost:5050/v1/audio/speech \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_api_key_here" \
  -d '{
    "model": "tts-1",
    "input": "Hello, I am your AI assistant! Just let me know how I can help bring your ideas to life.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

And an example of a language other than English:

```bash
curl -X POST http://localhost:5050/v1/audio/speech \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_api_key_here" \
  -d '{
    "model": "tts-1",
    "input": "ã˜ã‚ƒã‚ã€è¡Œãã€‚é›»è»Šã®æ™‚é–“ã€èª¿ã¹ã¦ãŠãã‚ˆã€‚",
    "voice": "ja-JP-KeitaNeural"
  }' \
  --output speech.mp3
```

##### Additional Endpoints

- **POST/GET /v1/models**: Lists available TTS models.
- **POST/GET /v1/voices**: Lists `edge-tts` voices for a given language / locale.
- **POST/GET /v1/voices/all**: Lists all `edge-tts` voices, with language support information.

:::info
The `/v1` is now optional. 

Additionally, there are endpoints for **Azure AI Speech** and **ElevenLabs** for potential future support if custom API endpoints are allowed for these options in Sage WebUI.

These can be disabled by setting the environment variable `EXPAND_API=False`.
:::

</details>

## ğŸ³ Dockerã®ã‚¯ã‚¤ãƒƒã‚¯è¨­å®š

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ã§ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã§ãã¾ã™

```bash
docker run -d -p 5050:5050 \
  -e API_KEY=your_api_key_here \
  -e PORT=5050 \
  -e DEFAULT_VOICE=en-US-AvaNeural \
  -e DEFAULT_RESPONSE_FORMAT=mp3 \
  -e DEFAULT_SPEED=1.0 \
  -e DEFAULT_LANGUAGE=en-US \
  -e REQUIRE_API_KEY=True \
  -e REMOVE_FILTER=False \
  -e EXPAND_API=True \
  travisvn/openai-edge-tts:latest
```

:::note
ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ã€å¯èª­æ€§ã¨ã‚µãƒãƒ¼ãƒˆã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚

ç’°å¢ƒå¤‰æ•°`REMOVE_FILTER=True`ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚’ç„¡åŠ¹ã«ã§ãã¾ã™ã€‚
:::

## è¿½åŠ ãƒªã‚½ãƒ¼ã‚¹

`openai-edge-tts`ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[GitHubãƒªãƒã‚¸ãƒˆãƒª](https://github.com/travisvn/openai-edge-tts)ã‚’ã”è¦§ãã ã•ã„

ç›´æ¥ã‚µãƒãƒ¼ãƒˆãŒå¿…è¦ãªå ´åˆã¯ã€[Voice AI & TTS Discord](https://tts.travisvn.com/discord)ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„

## ğŸ™ï¸ éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«

[éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã‚’å†ç”Ÿã—ã€åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã®Edge TTSéŸ³å£°ã‚’ç¢ºèªã™ã‚‹](https://tts.travisvn.com/)