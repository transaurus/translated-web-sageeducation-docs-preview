---
sidebar_position: 400
title: "⭐ Features"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Sage Open WebUIの主な機能 ⭐

- 🚀 **簡単なセットアップ**: DockerまたはKubernetes（`kubectl`、`kustomize`、`helm`）を使用してシームレスにインストール可能。Ollamaがバンドルされた`:ollama`イメージとCUDAサポート付きの`:cuda`イメージの両方をサポート。

- 🤝 **OpenAI API統合**: OpenAI互換APIを簡単に統合し、Ollamaモデルと並行して多様な会話が可能。OpenAI API URLをカスタマイズすることで、様々なサードパーティアプリケーションとSage Open WebUIをシームレスに連携可能。

- 🛡️ **詳細な権限設定とユーザーグループ**: 管理者がワークスペース全体で詳細なユーザーロール、ユーザーグループ、権限を設定可能。これによりセキュリティが強化されるだけでなく、カスタマイズされたユーザー体験を提供し、ユーザー間の所有感と責任感を促進。

- 📱 **レスポンシブデザイン**: デスクトップPC、ノートPC、モバイルデバイスでシームレスな体験を提供。

- 📱 **モバイル向けプログレッシブウェブアプリ**: モバイルデバイスでネイティブのようなPWA体験を実現。`localhost`または個人ドメインでオフラインアクセス可能なスムーズなUIを提供。PWAをインストール可能にするためには、安全なコンテキスト（通常はHTTPS経由）で配信される必要があります。
  - PWAを設定するには、Linux、Docker、および`Nginx`、`Caddy`、`Traefik`などのリバースプロキシに関する知識が必要です。これらのツールを使用することで、ニーズに合わせたPWAの構築とデプロイを効率化できます。「ワンクリックインストール」オプションはありませんが、これらのリソースを活用することでHTTPS経由で安全にSage Open WebUIインスタンスをデプロイするプロセスを簡素化できます。

- ✒️🔢 **完全なMarkdownとLaTeXサポート**: 充実したMarkdownとLaTeX機能により、LLM体験を向上。

- 🧩 **モデルビルダー**: Sage WebUIから直接ベースOllamaモデルを元にカスタムモデルを簡単に作成可能。[Sage WebUIコミュニティ](https://sage.education/)との統合により、カスタムキャラクターやエージェントの追加、モデル要素のカスタマイズ、モデルのインポートが容易に。

- 📚 **ローカルおよびリモートRAG統合**: チャット内で先進的なRetrieval Augmented Generation（RAG）技術を活用してドキュメントを探索可能。ドキュメントはワークスペースの`Documents`タブに読み込んだ後、クエリの前にポンド記号[`#`]を使用するか、プロンプトをポンド記号[`#`]で始めることでアクセス可能。ウェブページコンテンツを統合する場合はURLを続けて指定。

- 🔍 **RAG向けウェブ検索**: 様々な検索プロバイダーを選択してウェブ検索を実行し、結果をローカルのRAG体験に直接注入可能。

- 🌐 **ウェブブラウジング機能**: `#`コマンドに続けてURLを指定することで、ウェブサイトをチャット体験にシームレスに統合。これにより会話の豊かさと深みが増します。

- 🎨 **画像生成統合**: 画像生成機能をシームレスに統合し、ダイナミックなビジュアルコンテンツでチャット体験を充実。

- ⚙️ **並列モデル利用**: 複数のモデルを同時に活用し、それぞれの強みを活かした最適な応答を実現。多様なモデルモダリティを並行して利用することで体験を向上。

- 🔐 **ロールベースアクセス制御（RBAC）**: 許可された個人のみがOllamaにアクセス可能。モデルの作成とプル権限は管理者専用。

- 🌐🌍 **多言語サポート**: 国際化（`i18n`）サポートにより、好みの言語でSage WebUIを利用可能。サポート言語の拡充に協力してくれる貢献者を募集しています！

- 🌟 **継続的なアップデート**: 定期的なアップデート、修正、新機能追加によりSage WebUIの改善にコミット。

## その他にも多くの注目すべき機能が... ⚡️

---

### 🔧 パイプラインサポート

- 🔧 **パイプラインズフレームワーク**: モジュール型プラグインフレームワークを活用し、Sage WebUIの体験をシームレスに統合・カスタマイズ可能（https://github.com/Startr/pipelines）。AIエージェントからホームオートメーションAPIまで、Pythonライブラリの統合やカスタムロジックの追加が容易です。

- 📥 **アップロードパイプライン**: `管理パネル` > `設定` > `パイプラインズ`メニューから直接パイプラインをアップロード可能。パイプライン管理プロセスを効率化します。

#### 当社のパイプラインズフレームワークの可能性は無限大です。まずはいくつかの事前構築済みパイプラインから始めてみましょう！

- 🔗 **関数呼び出し**: [関数呼び出し](https://github.com/Startr/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)をパイプライン経由で統合し、高度な関数呼び出し機能でLLMインタラクションを強化。

- 📚 **カスタムRAG**: [カスタム検索拡張生成（RAG）](https://github.com/Startr/pipelines/tree/main/examples/pipelines/rag)パイプラインを統合し、独自のRAGロジックでLLMインタラクションを向上。

- 📊 **Langfuseによるメッセージ監視**: [Langfuse](https://github.com/Startr/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py)パイプラインでメッセージインタラクションをリアルタイムに監視・分析。

- ⚖️ **ユーザーレート制限**: [レートリミット](https://github.com/Startr/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py)パイプラインでAPI使用を効率的に管理し、レート制限超過を防止。

- 🌍 **LibreTranslateリアルタイム翻訳**: [LibreTranslate](https://github.com/Startr/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py)パイプラインでLLMインタラクションにリアルタイム翻訳を統合し、多言語コミュニケーションを実現。
  ※本パイプラインは動作にDockerコンテナ内のLibreTranslate追加設定が必要です。

- 🛡️ **有害メッセージフィルタリング**: [Detoxify](https://github.com/Startr/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py)パイプラインが有害メッセージを自動フィルタリングし、清潔で安全なチャット環境を維持。

- 🔒 **LLM-Guard**: [LLM-Guard](https://github.com/Startr/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py)パイプラインで安全なLLMインタラクションを確保。プロンプトインジェクションスキャナーが大規模言語モデルを標的とした巧妙な入力操作を検出・緩和します。

- 🕒 **会話ターン制限**: [会話ターン制限](https://github.com/Startr/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py)パイプラインでインタラクション管理を改善。

- 📈 **OpenAI生成統計**: [OpenAI](https://github.com/Startr/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py)パイプラインがOpenAIモデルの詳細な生成統計を提供。

- 🚀 **マルチモデルサポート**: [様々なプロバイダー](https://github.com/Startr/pipelines/tree/main/examples/pipelines/providers)のAIモデルとシームレスに統合。多様な言語モデルを選択・操作可能に。

#### 豊富な機能とカスタマイズオプションに加え、[すぐに使えるサンプルパイプラインライブラリ](https://github.com/Startr/pipelines/tree/main/examples)と[実用的なスキャフォールドパイプライン例](https://github.com/Startr/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py)を提供。これらのリソースが開発プロセスを効率化し、パイプラインズとPythonを使った強力なLLMインタラクションを迅速に構築可能にします。コーディングを楽しんでください！💡

---

### 🖥️ ユーザーエクスペリエンス

- 🖥️ **直感的なインターフェース**: チャットインターフェースはユーザーを念頭に設計されており、ChatGPTのユーザーインターフェースからインスピレーションを得ています。

- ⚡ **高速なレスポンス**: 信頼性の高い高速で応答性の高いパフォーマンスを楽しめます。

- 🎨 **スプラッシュスクリーン**: よりスムーズなユーザー体験のためのシンプルなローディングスプラッシュスクリーン。

- 🌐 **パーソナライズされたインターフェース**: 設定 > インターフェースから、新しくデザインされた検索ランディングページとクラシックなチャットUIを選択可能で、カスタマイズされた体験が可能です。

- 📦 **Pipインストール方法**: Sage Open WebUIのインストールは`pip install sage-open-webui`コマンドで実行可能で、プロセスを簡素化し、新規ユーザーにもアクセスしやすくなっています。詳細はこちらをご覧ください: https://pypi.org/project/sage-open-webui/。

- 🌈 **テーマカスタマイズ**: さまざまなオプションでSage WebUIの体験をパーソナライズできます。シックなソリッドテーマ、カスタマイズ可能なチャット背景画像、3つのモードオプション（ライト、ダーク、OLEDダークモード）から選択可能です。または、*Her*に選ばせることもできます！ ;)

- 🖼️ **カスタム背景サポート**: 設定 > インターフェースからカスタム背景を設定し、体験をパーソナライズできます。

- 📝 **Markdown対応のリッチバナー**: Markdownサポートにより、視覚的に魅力的なアナウンスを作成でき、よりリッチでダイナミックなコンテンツが可能です。

- 💻 **コードシンタックスハイライト**: シンタックスハイライト機能により、コードの可読性が向上し、明確で簡潔なビューが提供されます。

- 🗨️ **ユーザーメッセージのMarkdownレンダリング**: ユーザーメッセージがMarkdownでレンダリングされるようになり、可読性とインタラクションが向上しました。

- 🎨 **柔軟なテキスト入力オプション**: リッチテキスト入力とレガシーテキストエリア入力を切り替え可能で、ユーザーの好みに合わせて高度なフォーマットとシンプルなテキスト入力を選択できます。

- 👆 **簡単なコード共有**: コードブロック内のフローティングコピーボタンやコードスパンからのクリックでコピー機能など、便利なコード共有オプションにより、共有とコラボレーションのプロセスが効率化され、時間の節約とストレスの軽減が図れます。

- 🎨 **インタラクティブなアーティファクト**: WebコンテンツやSVGをインターフェースに直接レンダリングでき、クイックイテレーションとライブ変更をサポートし、創造性と生産性が向上します。

- 🖊️ **ライブコード編集**: 強化されたコードブロックにより、LLM応答内で直接ライブ編集が可能で、アーティファクトによるライブリロードがサポートされ、コーディングとテストが効率化されます。

- 🔍 **SVGの拡張インタラクション**: Mermaidダイアグラムを含むSVG画像のパンとズーム機能により、複雑な概念の深い探索と理解が可能になります。

- 🔍 **テキスト選択クイックアクション**: LLM応答でテキストがハイライトされるとフローティングボタンが表示され、「質問する」や「説明する」などの深いインタラクションが提供され、ユーザー体験が向上します。

- ↕️ **双方向チャットサポート**: 左から右、右から左のチャット方向を簡単に切り替えられ、さまざまな言語の好みに対応できます。

- 📱 **モバイルアクセシビリティ**: モバイルデバイスでは、シンプルなスワイプジェスチャーでサイドバーを開閉できます。

- 🤳 **対応デバイスでの触覚フィードバック**: Androidデバイスでは、特定のインタラクション時に没入型の触覚フィードバックがサポートされます。

- 🔍 **ユーザー設定検索**: 設定フィールドを素早く検索でき、使いやすさとナビゲーションが向上します。

- 📜 **オフラインSwaggerドキュメント**: 開発者向けのSwagger APIドキュメントにオフラインでアクセス可能で、どこでも完全なアクセシビリティが確保されます。

- 💾 **パフォーマンス最適化**: 大規模な依存関係のレイジーローディングにより、初期メモリ使用量が最小化され、パフォーマンスが向上し、ロード時間が短縮されます。

- 🚀 **永続的でスケーラブルな設定**: Sage Open WebUIの設定はデータベース（webui.db）に保存され、シームレスなロードバランシング、高可用性セットアップ、複数インスタンス間での永続的な設定が可能で、設定のアクセスと再利用が容易になります。

- 🔄 **ポータブルなインポート/エクスポート**: Sage Open WebUIの設定を簡単にインポート/エクスポートでき、複数システム間での設定の複製プロセスが簡素化されます。

- ❓ **ドキュメントとショートカットへのクイックアクセス**: メインUI画面の右下隅にあるクエスチョンマークボタン（デスクトップPCやラップトップなどの大きな画面で利用可能）から、Sage WebUIのドキュメントページと利用可能なキーボードショートカットに簡単にアクセスできます。

- 📜 **変更履歴と更新チェック**: ユーザーは設定 > について > 新機能を確認から、包括的な変更履歴にアクセスし、最新の機能、改善、バグ修正の概要を確認できるほか、更新をチェックできます。

---

### 💬 会話

- 💬 **真の非同期チャット**: 真の非同期チャットサポートにより、マルチタスキングが途切れることなく可能です。チャットを作成し、他の作業に移り、いつでも戻って準備完了の応答を確認できます。

- 🔔 **チャット完了通知**: 非アクティブなタブでチャットが完了した際に、UI内で即座に通知を受け取ることができ、応答を見逃すことはありません。

- 🌐 **通知Webhook統合**: タブが閉じられていても、長時間実行されるチャットや外部統合の必要性に対して設定可能なWebhook通知でタイムリーな更新を受け取れます。

- 📚 **チャネル（ベータ）**: Discord/SlackスタイルのチャットルームでユーザーとAI間のリアルタイムコラボレーションを探索し、チャネル用のボットを構築し、積極的なマルチエージェントワークフローのための非同期通信を解き放ちます。

- 🖊️ **チャネル内タイピングインジケーター**: チャネル内でのリアルタイムタイピングインジケーターにより、コラボレーションが強化され、全員が参加し情報を得られます。

- 👤 **ユーザーステータスインジケーター**: チャネル内でプロフィール画像をクリックすることで、ユーザーのステータスを素早く確認でき、調整と可用性の洞察が向上します。

- 💬 **チャットコントロール**: 各チャットセッションのパラメータを簡単に調整でき、インタラクションに対するより精密な制御が可能です。

- 💖 **お気に入り応答管理**: チャット概要から直接お気に入りの応答をマークし整理でき、好みの応答へのアクセスと検索が容易になります。

- 📌 **ピン留めチャット**: 重要な会話を簡単にアクセスできるように保持するためのピン留めチャットをサポートしています。

- 🔍 **RAG埋め込みサポート**: `Admin Panel` > `Settings` > `Documents`メニューで直接Retrieval Augmented Generation（RAG）埋め込みモデルを変更でき、ドキュメント処理が強化されます。この機能はOllamaおよびOpenAIモデルをサポートしています。

- 📜 **RAG機能での引用**: Retrieval Augmented Generation（RAG）機能により、LLMに供給されたドキュメントのコンテキストを引用付きで簡単に追跡できます。

- 🌟 **強化されたRAGパイプライン**: RAG埋め込み機能のトグル可能なハイブリッド検索サブ機能で、`BM25`によるRAG機能が強化され、`CrossEncoder`による再ランキングと設定可能な関連性スコア閾値が提供されます。

- 📹 **YouTube RAGパイプライン**: 動画URL経由でYouTube動画を要約する専用のRetrieval Augmented Generation（RAG）パイプラインにより、動画の文字起こしと直接スムーズにやり取りできます。

- 📁 **包括的なドキュメント取得**: 完全なドキュメント取得と従来のスニペット間で切り替えられ、要約などの包括的なタスクや強化されたドキュメント機能をサポートします。

- 🌟 **RAG引用の関連性**: RAG結果に関連性パーセンテージが追加され、引用の正確性を簡単に評価できます。

- 🗂️ **高度なRAG**: 検索前に最適なクエリを決定するためのチャット履歴のスマートな前処理により、RAGの精度が向上します。

- 📚 **RAGのインライン引用**: Retrieval-Augmented Generation（RAG）応答に対してシームレスなインライン引用が提供され、トレーサビリティが向上し、新しくアップロードされたファイルのソースが明確になります。

- 📁 **大きなテキストの処理**: 大きな貼り付けテキストをオプションでファイルアップロードに変換し、RAGで直接使用できるようにして、チャットインターフェースを整理された状態に保ちます。

- 🔄 **マルチモーダルサポート**: 画像（例: `LLaVA`）を含むマルチモーダルインタラクションをサポートするモデルと簡単にやり取りできます。

- 🤖 **複数モデルサポート**: 多様なチャットインタラクションのために異なるモデル間で素早く切り替えられます。

- 🔀 **複数モデルチャットでの応答統合**: 複数のモデルからの応答を単一の首尾一貫した返信に統合することで、対話が強化されます。

- ✅ **チャット内での同一モデルの複数インスタンス**: 同じモデルの複数インスタンスの追加をサポートするように多くのモデルチャットが強化されました。

- 💬 **一時チャット機能**: ユーザーインタラクションの柔軟性を高めるため、一時チャット機能が導入され、古いチャット履歴設定は非推奨となりました。

- 🖋️ **ユーザーメッセージ編集**: ユーザーチャット編集機能が強化され、変更を送信せずに保存できるようになりました。

- 💬 **効率的な会話編集**: Cmd/Ctrl+Shift+Enterショートカットを使用して、新しいメッセージペアを迅速かつ直感的に作成でき、会話の長さのテストが効率化されます。

- 🖼️ **クライアント側画像圧縮**: 設定 > インターフェースからアップロード前に画像を圧縮できるクライアント側画像圧縮により、帯域幅を節約しパフォーマンスを向上させます。

- 👥 **「@」モデル統合**: 会話中にアクセス可能なローカルまたは外部モデルにシームレスに切り替えることで、単一のチャット内で複数のモデルの集合知を活用できます。これは、チャット内でモデル名を指定するために`@`コマンドを使用することで実現できます。

- 🏷️ **会話タグ付け**: 効率的な「tag:」クエリシステムを使用して、タグ付けされたチャットをカテゴリ分けし迅速に参照できるようにし、インターフェースを散らかすことなく会話を管理、検索、整理できます。

- 🧠 **自動タグ付け**: 会話はオプションで自動的にタグ付けされ、自動生成タイトルの効率性を反映した整理が可能です。

- 👶 **チャットクローン作成**: 将来の参照や継続のために任意のチャットのスナップショットを簡単にクローンして保存できます。この機能により、中断したところから再開したり、セッションを他の人と共有したりすることが容易になります。チャットのコピーを作成するには、チャットのドロップダウンオプションにある`Clone`ボタンをクリックするだけです。クローンに追いつけますか？

- ⭐ **視覚化された会話フロー**: インタラクティブなメッセージ図により、会話フローの視覚化が改善され、複雑な議論の理解とナビゲーションが向上します。

- 📁 **チャットフォルダー**: チャットをフォルダーに整理し、ドラッグアンドドロップで簡単に管理し、共有や分析のためにシームレスにエクスポートできます。

- 📤 **簡単なチャットインポート**: サイドバーにチャットエクスポート（JSON）をドラッグアンドドロップするだけで、ワークスペースにチャットをインポートできます。

- 📜 **プロンプトプリセットサポート**: チャット入力で`/`コマンドを使用してカスタムプリセットプロンプトに即座にアクセスできます。事前定義された会話スターターを簡単にロードし、インタラクションを迅速化します。[Sage Open WebUI Community](https://openwebui.com/)統合を通じてプロンプトを簡単にインポートしたり、独自のプロンプトを作成したりできます！

- 📅 **プロンプト変数サポート**: システムプロンプトまたはチャット内で直接プロンプトを選択するスラッシュコマンドを使用して、`{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}`、`{{USER_LOCATION}}`などのプロンプト変数を利用できます。
  - `{{USER_LOCATION}}`プロンプト変数を使用するには、HTTPSを介した安全な接続が必要です。この特定のプロンプト変数を使用するには、`Settings` > `Interface`メニューから`{{USER_LOCATION}}`が有効になっていることを確認してください。
  - `{{CLIPBOARD}}`プロンプト変数を使用するには、デバイスのクリップボードへのアクセスが必要です。

- 🧠 **メモリ機能**: `Settings` > `Personalization` > `Memory`メニューから、LLMに覚えさせたい情報を手動で追加できます。メモリは追加、編集、削除が可能です。

---

### 💻 モデル管理

- 🛠️ **モデルビルダー**: すべてのモデルは、モデル編集ページ内の永続的なモデルビルダーモードで構築および編集できます。

- 📚 **モデル向けナレッジサポート**: モデルの編集ページから直接ツール、関数、ナレッジコレクションをモデルにアタッチする機能により、各モデルが利用できる情報が強化されます。

- 🗂️ **モデルプリセット**: OllamaおよびOpenAI API向けのモデルプリセットを作成および管理できます。

- 🏷️ **モデルタグ付け**: モデルワークスペースでは、タグを使用してモデルを整理できます。

- 📋 **モデルセレクタードロップダウン順序付け**: モデルワークスペース内でモデルをドラッグアンドドロップして希望の位置に簡単に整理でき、変更はモデルドロップダウンメニューに反映されます。

- 🔍 **モデルセレクタードロップダウン**: ファジー検索と詳細なモデル情報（モデルタグやモデル説明を含む）で、簡単にモデルを見つけて選択できます。

- ⌨️ **矢印キーによるモデル選択**: 矢印キーを使用してモデルをより速く選択でき、アクセシビリティが向上します。

- 🔧 **モデルワークスペースのクイックアクション**: Shiftキーを使用したクイックアクションが強化され、モデルワークスペースでモデルを非表示/表示および削除できます。

- 😄 **透明なモデル使用状況**: ナレッジ拡張モデルを使用したクエリ中のシステム状態について、可視化されたステータス表示により常に情報を得られます。

- ⚙️ **高度なパラメータによる微調整制御**: `seed`、`temperature`、`frequency penalty`、`context length`、`seed`などのモデルパラメータを調整することで、より深いレベルの制御が可能です。

- 🔄 **シームレスな統合**: [Ollamaライブラリ](https://ollama.com/library/)のモデルページから任意の`ollama run {model:tag}` CLIコマンドをコピーし、モデルドロップダウンに貼り付けることで、簡単にモデルを選択してプルできます。

- 🗂️ **Ollama Modelfileの作成**: Ollama向けのモデルファイルを作成するには、`Admin Panel` > `Settings` > `Models` > `Create a model`メニューに移動します。

- ⬆️ **GGUFファイルからのモデル作成**: Sage WebUIから直接GGUFファイルをアップロードしてOllamaモデルを簡単に作成できます。`Admin Settings` > `Settings` > `Model` > `Experimental`メニューから、マシンからのアップロードまたはHugging FaceからのGGUFファイルのダウンロードを選択できます。

- ⚙️ **デフォルトモデル設定**: 新しいチャットのデフォルトモデル設定は、モバイルデバイスの`Settings` > `Interface`メニューで設定できます。デスクトップPCやラップトップでは、モデルセレクタードロップダウンでより簡単に設定できます。

- 💡 **LLM応答のインサイト**: 外部モデルAPIのインサイトや包括的なローカルモデル情報を含む、すべての生成された応答の詳細を表示できます。

- 🕒 **一目でわかるモデル詳細**: モデルハッシュや最終更新タイムスタンプなどの重要なモデル詳細を、モデルワークスペースで直接表示でき、追跡と管理が強化されます。

- 📥🗑️ **モデルのダウンロード/削除**: Sage Open WebUIから直接モデルをダウンロードまたは削除できます。

- 🔄 **すべてのOllamaモデルの更新**: 1回の操作ですべてのローカルにインストールされたモデルを更新できる便利なボタンにより、モデル管理が効率化されます。

- 🍻 **TavernAIキャラクターカード統合**: モデルビルダーでのTavernAIキャラクターカード統合により、視覚的なストーリーテリングが強化されます。ユーザーはTavernAIキャラクターカードPNGをモデルファイルに直接組み込むことができ、より没入感のあるユーザー体験を実現できます。

- 🎲 **モデルプレイグラウンド（ベータ）**: モデルプレイグラウンドエリア（`ベータ`）でモデルを試すことができます。この機能により、ユーザーはライブチャット環境にデプロイする前に、サンドボックス環境でモデルの機能やパラメータを簡単にテストおよび探索できます。

---

### 👥 コラボレーション

- 🗨️ **ローカルチャット共有**: ユーザー間で効率的かつシームレスにチャットリンクを生成・共有でき、コラボレーションとコミュニケーションを強化します。

- 👍👎 **RLHFアノテーション**: メッセージに対して👍または👎で評価し、1-10段階でレスポンスを評価した後、テキストフィードバックを提供可能。これにより人間のフィードバックからの強化学習（`RLHF`）用データセット作成を容易にします。ローカル保存データの機密性を保ちつつ、メッセージをモデルのトレーニングやファインチューニングに活用できます。

- 🔧 **包括的フィードバックエクスポート**: フィードバック履歴データをJSON形式でエクスポート可能。RLHF処理や詳細分析とのシームレスな連携を実現し、改善のための貴重なインサイトを提供します。

- 🤝 **コミュニティ共有**: `Sage Open WebUIコミュニティに共有`ボタンをクリックして、チャットセッションを[Sage Open WebUIコミュニティ](https://openwebui.com/)と共有可能。この機能により他ユーザーと交流し、プラットフォーム上で共同作業ができます。
  - 本機能を利用するにはSage Open WebUIコミュニティアカウントへのサインインが必要です。チャット共有は活発なコミュニティ形成、知識共有、共同問題解決を促進します。なおチャットセッションのコミュニティ共有はオプション機能で、`管理者設定` > `設定` > `一般`メニューで管理者のみが有効/無効を切り替えられます。

- 🏆 **コミュニティリーダーボード**: ELOレーティングシステムを採用したリアルタイムリーダーボードで競い合い、パフォーマンスを追跡可能。フィードバック履歴の共有もオプションで選択できます。

- ⚔️ **モデル評価アリーナ**: 管理者設定からブラインドA/Bテストを実施可能。モデルを真に並列比較でき、ニーズに最適なモデルを見つけるのが容易になります。

- 🎯 **トピックベースランキング**: 実験的なトピックベース再ランキングシステムにより、フィードバック内のタグ類似度に基づいてリーダーボード順位を調整。より正確なランキングを発見できます。

- 📂 **統合型コラボレーションワークスペース**: モデルファイル、プロンプト、ドキュメント、ツール、関数を一元的に管理可能。複数ユーザーがモデル・ナレッジ・プロンプト・ツールへ共同編集できるため、ワークフロー効率化とチームワーク強化を実現します。

---

### 📚 履歴とアーカイブ

- 📜 **チャット履歴**: チャットナビゲーションサイドバーから会話履歴に簡単にアクセス・管理可能。`設定` > `チャット`メニューでチャット履歴を無効にすると、新規インタラクション時に履歴が作成されなくなります。

- 🔄 **再生成履歴アクセス**: LLMレスポンスの全再生成履歴を簡単に再訪・探索可能。

- 📬 **チャットアーカイブ**: 完了した会話を将来の参照用に手軽に保管可能。整理された使いやすいチャットインターフェースを維持します。

- 🗃️ **全チャット一括アーカイブ**: すべてのチャットを一度に素早くアーカイブできます。

- 📦 **アーカイブ済み全チャットのJSONエクスポート**: アーカイブ済みチャットを単一JSONファイルに簡単にエクスポート可能。バックアップや転送用途に利用できます。

- 📄 **JSON/PDF/TXT形式での個別チャットダウンロード**: 各チャットを`.json`、`.pdf`、`.txt`形式で個別にダウンロード可能。

- 📤📥 **チャット履歴のインポート/エクスポート**: `チャットのインポート`と`チャットのエクスポート`オプションで、チャットデータをプラットフォーム内外にシームレスに移動可能。

- 🗑️ **全チャット削除**: すべてのチャットを完全に削除するオプションで、新たなスタートを切れます。

---

### 🎙️ オーディオ、音声、アクセシビリティ

- 🗣️ **音声入力サポート**: 音声インタラクションを通じてモデルと対話可能。直接モデルに話しかける便利さを体験できます。また、3秒間の無音後に自動的に音声入力を送信するオプションも用意されており、よりスムーズな操作が可能です。
  - マイクへのアクセスにはHTTPS経由の安全な接続を手動で設定する必要があります。または[自己責任でURLを手動でホワイトリストに追加](/troubleshooting/microphone-error)することも可能です。

- 😊 **絵文字コール**: `設定` > `インターフェース`メニューからこの機能を有効にすると、音声通話中にLLMが絵文字を使って感情を表現できるようになり、よりダイナミックな対話が可能になります。
  - この機能を使用するにはHTTPS経由の安全な接続でマイクへのアクセスが必要です。

- 🎙️ **ハンズフリー音声通話機能**: 手を使わずに音声通話を開始でき、よりシームレスな対話が実現します。
  - この機能を使用するにはHTTPS経由の安全な接続でマイクへのアクセスが必要です。

- 📹 **ビデオ通話機能**: LlaVAやGPT-4oなどのビジョンモデルをサポートしたビデオ通話が可能で、コミュニケーションに視覚的要素を追加できます。
  - この機能を使用するにはHTTPS経由の安全な接続でカメラとマイクへのアクセスが必要です。

- 👆 **タップで中断**: モバイルデバイスでの音声会話中にAIの発話を簡単なタップで停止でき、対話をスムーズに制御できます。

- 🎙️ **音声中断**: モバイルデバイスでの音声会話中に音声でAIの発話を停止でき、対話をスムーズに制御できます。

- 🔊 **設定可能なテキスト読み上げエンドポイント**: OpenAI互換の設定可能なエンドポイントで、LLM応答の読み上げ体験をカスタマイズできます。

- 🔗 **ダイレクトコールモードアクセス**: URLから直接コールモードを起動でき、モバイルデバイスユーザーにとって便利なショートカットとなります。

- ✨ **カスタマイズ可能なテキスト読み上げ**: テキスト読み上げ(TTS)生成リクエスト用のメッセージコンテンツの分割方法を制御でき、柔軟な音声出力オプションを提供します。

- 🔊 **Azure Speech Services統合**: テキスト読み上げ(TTS)にAzure Speech servicesをサポートし、より幅広い音声合成オプションを提供します。

- 🎚️ **カスタマイズ可能なオーディオ再生**: コールモード設定でオーディオ再生速度を調整可能で、アクセシビリティと使いやすさが向上します。

- 🎵 **広範なオーディオ互換性**: 'audio/x-m4a'を含む幅広いオーディオファイル形式の文字起こしをRAGでサポートし、プラットフォーム内のオーディオコンテンツとの互換性を拡大します。

- 🔊 **オーディオ圧縮**: 実験的なオーディオ圧縮により、OpenAIの音声認識処理における25MB制限を回避可能で、音声ベースのインタラクションの可能性が広がります。

- 🗣️ **実験的SpeechT5 TTS**: ローカルSpeechT5サポートにより、テキスト読み上げ機能が向上します。

---

### 🐍 コード実行

- 🚀 **多用途でUIに依存しないOpenAI互換プラグインフレームワーク**: [Sage WebUI Pipelines](https://github.com/Startr/pipelines)をシームレスに統合・カスタマイズ可能で、効率的なデータ処理とモデルトレーニングを実現し、究極の柔軟性と拡張性を提供します。

- 🛠️ **ネイティブPython関数呼び出し**: Sage WebUI内で直接Pythonの力を活用可能。組み込みコードエディタを使用して、カスタムRAGパイプライン、ウェブ検索ツール、さらにはエージェントのようなアクションまで、`ツール`と`関数`ワークスペース内で関数コードをシームレスに開発・統合できます。

- 🐍 **Pythonコード実行**: Pyodide経由でブラウザ上でPythonコードをローカル実行可能。Pyodideがサポートする様々なライブラリが利用できます。

- 🌊 **Mermaidレンダリング**: [Mermaidダイアグラミングツール](https://mermaid.js.org/intro/)を使用して、Sage WebUI内で直接視覚的に魅力的なダイアグラムやフローチャートを作成可能。Mermaid構文のレンダリングをサポートします。

- 🔗 **Iframeサポート**: 関数やツールを使用してHTMLをチャットインターフェースに直接レンダリングできます。

---

### 🔒 統合とセキュリティ

- ✨ **複数のOpenAI互換APIサポート**: 様々なOpenAI互換APIをシームレスに統合・カスタマイズ可能で、チャットインタラクションの汎用性を向上させます。

- 🔑 **簡素化されたAPIキー管理**: OpenAIライブラリと連携するためのシークレットキーを簡単に生成・管理でき、統合と開発を効率化します。

- 🌐 **HTTP/Sプロキシサポート**: `http_proxy`または`https_proxy`環境変数を使用してネットワーク設定を簡単に構成可能。これらの変数が設定されている場合、それぞれHTTPおよびHTTPSプロキシのURLを含める必要があります。

- 🌐🔗 **外部Ollamaサーバー接続**: 環境変数を設定することで、異なるアドレスでホストされている外部Ollamaサーバーにシームレスに接続できます。

- 🛢️ **柔軟なデータベース統合**: SQLite、Postgres、Milvusなどの複数のベクターデータベースを含むカスタムデータベースに環境変数を使用してシームレスに接続し、柔軟でスケーラブルなデータ管理を実現します。

- 🌐🗣️ **外部音声認識（STT）サポート**: 外部音声認識（STT）サービスの追加により、ユーザーは好みのプロバイダを選択してシームレスなインタラクションを実現できます。

- 🌐 **リモートChromaDBサポート**: リモートChromaDBサーバーに接続することで、データベースの機能を拡張できます。

- 🔀 **複数Ollamaインスタンスの負荷分散**: 複数のOllamaインスタンス間でチャットリクエストを簡単に分散させ、パフォーマンスと信頼性を向上させます。

- 🚀 **高度な負荷分散と信頼性**: 強化された負荷分散機能、完全なRedisサポートを備えたステートレスインスタンス、自動Webソケット再接続を活用し、複数インスタンス間でのシームレスで中断のないインタラクションを確保します。

- ☁️ **実験的S3サポート**: S3サポートを有効にしたステートレスWebUIインスタンスにより、スケーラビリティと重いワークロードのバランスを向上させます。

- 🛠️ **ユーザーグループ向けOAuth管理**: OAuth統合によるグループレベルの管理で、協調環境における制御とスケーラビリティを強化します。

---

### 👑 管理

- 👑 **スーパー管理者の自動割り当て**: 最初にサインアップしたユーザーをスーパー管理者として自動的に割り当てます。この役割は他の管理者を含め誰も変更できません。

- 🛡️ **詳細なユーザー権限制御**: カスタマイズ可能なロールベースの権限でユーザーの操作やアクセスを制限し、特定のタスクを許可されたユーザーのみが実行できるようにします。

- 👥 **マルチユーザー管理**: ページネーション機能付きの直感的な管理者パネルで、複数のユーザーをシームレスに管理でき、ユーザー管理の効率化とライフサイクル管理を簡素化します。

- 🔧 **管理者パネル**: ユーザー管理システムは、ユーザーのオンボーディングと管理を効率化するように設計されており、直接追加またはCSVインポートによる一括追加が可能です。

- 👥 **アクティブユーザー表示機能**: アクティブなユーザー数と誰がどのモデルを利用しているかを監視し、ユーザー数が多い場合のパフォーマンス影響を把握するのに役立ちます。

- 🔒 **デフォルトサインアップ権限**: 新規サインアップ時のデフォルト権限を「pending」「user」「admin」から指定可能。新規ユーザーの権限とアクセスレベルを柔軟に管理できます。

- 🔒 **新規サインアップ防止**: 新規ユーザー登録を無効化するオプションを有効にし、プラットフォームへのアクセスを制限してユーザー数を固定できます。

- 🔒 **チャット削除防止**: 管理者が設定を切り替えることで、すべてのユーザーがチャットメッセージを削除できないようにし、監査やコンプライアンス目的で全てのチャットを保持します。

- 🔗 **Webhook連携**: 新規ユーザー登録イベントをWebhook（Discord、Google Chat、Slack、Microsoft Teams対応）で購読し、リアルタイム通知と自動化機能を提供します。

- 📣 **設定可能な通知バナー**: 管理者はconfig.jsonで永続化可能なカスタマイズバナーを作成でき、内容、背景色（info、warning、error、success）、非表示設定が可能。ログインユーザーのみに表示されるため機密情報を保護します。

- 🛡️ **モデルホワイトリスト**: 管理者が「user」ロールのユーザー向けにモデルをホワイトリスト登録でき、許可されたモデルのみアクセス可能にすることでセキュリティとアクセス制御を強化。

- 🔑 **コミュニティ共有の管理者制御**: 管理者は「Admin Panel」＞「Settings」メニューのトグルで全ユーザーのコミュニティ共有を有効/無効化可能。セキュアな環境を維持しつつ、「Share on Community」ボタンの表示を制御できます。

- 📧 **信頼済みメール認証**: オプションで信頼済みメールヘッダーを使用した認証を追加し、Sage WebUIインスタンスのセキュリティ層を強化。

- 🔒 **バックエンドリバースプロキシサポート**: Sage WebUIバックエンドとOllama間の直接通信でセキュリティを強化。OllamaをLANに公開する必要がなくなり、/ollama/apiルートへのリクエストはバックエンドからOllamaにシームレスにリダイレクトされます。

- 🔒 **認証**: Sage WebUIはSSO、OAuth、SAML、OIDCなどの連携認証をネイティブサポートしませんが、認証リバースプロキシに委譲することでSSO体験を実現可能。既存認証システムと統合し、ユーザーアクセスを一元管理できます。詳細は[連携認証サポート](/features/sso)を参照。

- 🔓 **オプション認証無効化**: WEBUI_AUTHをFalseに設定し認証を無効化可能。既存ユーザーがいない新規インストールやデモ用途に最適。

- 🚫 **高度なAPIセキュリティ**: カスタムモデルフィルタに基づきAPIユーザーをブロックし、APIアクセス制御を強化。

- ❗ **管理者向け更新通知**: 管理者はログイン時に即座に更新通知を受け取り、最新の変更やシステム状況を把握可能。

- 👥 **ユーザーグループ管理**: ユーザーグループを作成・管理し、組織と制御を効率化。

- 🔐 **グループベースのアクセス制御**: ユーザーグループごとにモデル、ナレッジ、プロンプト、ツールへの詳細なアクセスを設定し、より制御された安全な環境を構築。

- 🛠️ **詳細なユーザー権限管理**: ワークスペース権限（ファイルアップロード/削除/編集、一時チャット）やモデル/ナレッジ/プロンプト/ツール作成を容易に管理。

- 🔑 **LDAP認証**: LDAPサポートでユーザー管理のセキュリティと拡張性を向上。

- 🌐 **カスタマイズ可能なOpenAI接続**: プレフィックスIDサポートや明示的なモデルIDサポートを含むカスタムOpenAI設定でスムーズに操作。

- 🔐 **Ollama APIキー管理**: プレフィックスIDサポートを含むOllama認証情報を安全かつ効率的に管理。

- 🔄 **接続管理**: 個々のOpenAIおよびOllama接続を必要に応じて有効/無効化可能。

- 🎨 **直感的なモデルワークスペース**: ユーザーとグループ間でモデルを管理する再設計されたユーザーフレンドリーなインターフェース。

- 🔑 **APIキー認証**: APIキー認証を簡単に有効/無効化し、セキュリティを強化。

- 🔄 **統合モデルリセット**: 管理者設定から全てのモデルをワンクリックでリセット・削除可能。

- 🔓 **柔軟なモデルアクセス制御**: 信頼環境では「BYPASS_MODEL_ACCESS_CONTROL」環境変数でユーザーロールのモデルアクセス制御を簡単にバイパス可能。

- 🔒 **設定可能なAPIキー認証制限**: APIキー認証のエンドポイント制限を柔軟に設定可能（デフォルトはオフで信頼環境でのセットアップが容易）。

---